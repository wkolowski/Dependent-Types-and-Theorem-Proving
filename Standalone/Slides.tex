\documentclass{beamer}

\usepackage{xcolor}

\newcommand{\m}[1]{\texttt{#1}}
\newcommand{\e}[1]{\textbf{#1}}

\title{Dependent Types and Theorem Proving: \\Introduction to Dependent Types}
\author{Wojciech KoÅ‚owski}
\date{November 2021}

\usetheme{Darmstadt}

\begin{document}

\frame{\titlepage}

\section{Greetings}

\begin{frame}{Prerequisites}
\begin{itemize}
	\item To understand what we will be talking about, you should have a working knowledge of F\# and the basic concepts of functional programming, namely:
	\item All about types: algebraic data types, sum types, product types, record types, pattern matching etc.
	\item All about functions: functions as first-class citizens, higher-order functions, recursive functions, currying etc.
	\item Even if you know these, you may be unfamiliar with the particular names -- for example, ``sum types'' is a name used in academia and Haskell, but in F\# they are better known as ``discriminated unions''.
\end{itemize}
\end{frame}

\begin{frame}{Learning outcomes}
\begin{itemize}
	\item You will get basic familiarity with the ideas behind all dependently typed languages.
	\item You will learn about all the different kinds of dependent types and what they are good for.
	\item You will be able to continue learning about dependent types on your own and won't be put off by all those obscure, scary and mysterious names and notations.
	%\item Bonus: you will begin to see logic and mathematics in a very different light, much closer to your day job (at least if you are a programmer working in F\#).
\end{itemize}
\end{frame}

\frame{\tableofcontents}

\begin{frame}{Introducing F*}
\begin{itemize}
	\item F* (pronounced ``eff star'') is a general-purpose purely functional programming language.
	\item Member of the ML family, syntactically most similar to F\#.
	\item Aimed at program verification.
	\item Dependent types.
	\item Refinement types.
	\item Effect system.
	%\item Not a .NET language.
	%\item Neither compiled nor interpreted -- it's a proof assistant, i.e. just a typechecker.
	%\item To run a program, it has to be extracted to some other language, like F\#, OCaml, C or WASM, and then compiled.
\end{itemize}
\end{frame}

\begin{frame}{Useful links}
\begin{itemize}
	\item \textbf{Repo with all lecture materials}: \url{https://github.com/wkolowski/Dependent-Types-and-Theorem-Proving}
	\item \textbf{You can run F* inside your browser} (and have a nice tutorial guide you): \url{http://www.fstar-lang.org/tutorial/}
	\item GitHub: \url{https://github.com/FStarLang/FStar}
	\item Homepage: \url{http://www.fstar-lang.org/}
	\item Download: \url{http://www.fstar-lang.org/\#download}
	\item Papers (not approachable for ordinary mortals): \url{http://www.fstar-lang.org/\#papers}
	\item Talks/presentations (more approachable): \url{http://www.fstar-lang.org/\#talks} (some of these are quite approachable if you're interested)  
\end{itemize}
\end{frame}

\begin{frame}{Code snippet no 1 - basics of F*}
\begin{itemize}
	\item We will now see some code that shows how these prerequisites look in F* (hint: basically the same as in F\#).
	\item See the file \texttt{Lecture1/Code/Prerequisites.fst}.
\end{itemize}
\end{frame}

\section{Why}

\begin{frame}{Why should we care about dependent types? 1/3}
\begin{itemize}
	\item Programs written in dynamically typed languages perform a lot of runtime checks.
	\item Beyond a certain size \textbf{dynamically typed software is hard to extend, refactor and maintain because errors manifest very late} in the development process, i.e. at runtime.
	\item Statically typed languages make the situation better, because they move typechecking to compile time, which means a lot of errors get caught much sooner.
	\item \textbf{Static typing is good}.
\end{itemize}
\end{frame}

\begin{frame}{Why should we care about dependent types? 2/3}
\begin{itemize}
	\item But in simple functional languages like F\# there's still plenty of runtime checks -- division by zero, taking the head of empty list and a lot of user-defined checks which throw exceptions in case of failure.
	\item With dependent types, all runtime checks can be turned into static checks -- \textbf{all errors are type errors}.
	\item This results in more extensible, refactorable and maintainable software (and also better performance -- less stuff to do at runtime).\item We can not only get rid of runtime checks, dependent types can also replace most unit tests and property tests.
	\item \textbf{Dependent types bring static typing to its limits}.
\end{itemize}
\end{frame}

\begin{frame}{Why should we care about dependent types? 3/3}
\begin{itemize}
	\item And when I say all errors are typing errors, I really mean it -- with dependent types, we can express all properties, formulate all specifications and describe all mathematical objects.
	\item \textbf{Dependent types reveal a deep connection between functional programming and logic}.
	\item Despite their great power, dependent types are easy to understand and significantly simplify the language design.
	\item Have you ever heard about fancy Haskell stuff like multi-param typeclasses, GADTs, higher-rank types, higher-kinded types, existential types and so on?
	\item No? No problem -- \textbf{with dependent types, we get all of that (and much more) for free}.
\end{itemize}
\end{frame}

\section{Examples}

\begin{frame}{Matrix multiplication}
\begin{itemize}
	\item We can only multiply matrices whose dimensions match, i.e. we can multiply an $n \times m$ matrix by a $m \times k$ and get an $n \times k$ matrix as a result.
	\item How to model this in our favourite programming language without dependent types?
	\item The best we can do is to have \textbf{a type of matrices} \m{Matrix} and then matrix multiplication has type \m{matmult :\ Matrix -> Matrix -> Matrix}.
	\item What happens when we call it with matrices of the wrong dimensions?
	\item $\m{matmult} \begin{bmatrix}1 & 2\\3 & 4\end{bmatrix} \begin{bmatrix}1 & 2 & 3\\4 & 5 & 6\\7 & 8 & 9\end{bmatrix}$ \textbf{is well-typed, but will throw} an \m{IllegalArgumentException} or some other kind of runtime error, or maybe it will crash even less gracefully.
\end{itemize}
\end{frame}

\begin{frame}{Matrix multiplication with dependent types}
\begin{itemize}
	\item In a language with dependent types we can define \m{Matrix n m}, \textbf{the type of $n \times m$ matrices}, and give multiplication the type \m{matmult : (n :\ $\mathbb{N}$) ->  (m :\ $\mathbb{N}$) -> (k :\ $\mathbb{N}$) -> Matrix n m -> Matrix m k -> Matrix n k}
	\item Now \m{matmult} is a function which takes five arguments: the three matrix dimensions and the two matrices themselves.
	\item After giving it the dimensions of the first matrix from the previous slide, \m{matmult 2 2} has type \m{(k :\ $\mathbb{N}$) -> Matrix 2 2 -> Matrix 2 3 -> Matrix 2 3}.
	\item It is clear that \m{matmult 2 2 k} $\begin{bmatrix}1 & 2\\3 & 4\end{bmatrix} \begin{bmatrix}1 & 2 & 3\\4 & 5 & 6\\7 & 8 & 9\end{bmatrix}$ \textbf{is not well-typed} for any \m{k}, because the last argument is of type \m{Matrix 3 3}, but an argument of type \m{Matrix 2 k} was expected.
\end{itemize}
\end{frame}

\begin{frame}{Array access}
\begin{itemize}
	\item When accessing the $i$-th element of an array, $i$ must be smaller than the length of the array.
	\item How to model this in our favourite programming language without dependent types?
	\item We can define \m{Array a}, \textbf{the type of arrays that hold elements of type} \m{a}, and we can access its elements with a function \m{get :\ Array a -> int -> a}.
	\item What happens, when $i$ is greater than the length of the array? Or, what happens when $i$ is negative?
	\item \m{get [| 'a'; 'b'; 'c' ] 5} is well-typed, but will throw an \m{IndexOutOfBoundsException} or result in a segmentation fault.
\end{itemize}
\end{frame}

\begin{frame}{Array access with dependent types}
\begin{itemize}
	\item In a language with dependent types we can define \m{Array a n}, \textbf{the type of arrays of length $n$ that hold elements of type} \m{a}, and we give array access the type \m{get :\ (n :\ $\mathbb{N}$) -> Array a n -> (i :\ int\{0 <= i < n \}) -> a}.
	\item We use refinement types (which we will cover later today) to statically guarantee that \m{i} isn't out of bounds.
	\item \m{get 3 [| 'a'; 'b'; 'c' |] 5} is not well-typed, because the typechecker can't prove \m{0 <= 5 < 3}, and thus \m{5} is not of type \m{int\{0 <= 5 < 3\}}.
\end{itemize}
\end{frame}

\section{The Universe}

\begin{frame}{Values and types}
\begin{itemize}
	\item To understand dependent types, first we have to be aware of the distinction between \textbf{values} and \textbf{types} that is present in all the usual mainstream programming languages.
	\item By \textbf{values}, we mean the bread-and-butter of programming: numbers, strings, arrays, lists, functions, etc.
	\item It should be pretty obvious to you that in most languages, \textbf{types} are not of the same status as numbers or functions.
\end{itemize}
\end{frame}

\begin{frame}{Dependencies}
\begin{itemize}
	\item Dependency is easy to understand. In fact, if you know basic F\#, then you already know most of it, because in F\#:
	\item \textbf{Values can depend on values}: we can think that the sum \m{n + m} is a number that depends on the numbers \m{n} and \m{m}. This dependency can be expressed as a \textbf{function}: \m{fun (n m :\ int) -> n + m}.
	\item \textbf{Values can depend on types}: for example, the identity function \m{fun (x :\ 'a) -> x} depends on the type \m{'a}. This kind of dependency is called \textbf{generics} (or, in academia, \textbf{polymorphism}).
	\item \textbf{Types can depend on types}: for example, the F\# type \m{Set<'a>} depends on the type \m{'a}. This kind of dependency is called \textbf{type operators}.
\end{itemize}
\end{frame}

\begin{frame}{Dependent types}
\begin{itemize}
	\item There's yet another kind of dependency, which is not present in F\#, but is present in F* and is the topic of this lecture.
	\item \textbf{Types can depend on values}: \textbf{dependent types}.
	\item Given a functional language like F\#, how to enable types to depend on values?
	\item Of course we want to retain the other kinds of dependencies (values on values, values on types, types on types).
\end{itemize}
\end{frame}

\begin{frame}{Juggling dependencies}
\begin{itemize}
	\item It turns out it's best \textbf{throw away all kinds of dependencies besides the basic one} (values on values)\dots
	\item \dots and then \textbf{turn types into values}!
	\item In other words: we want to make types first-class citizens of our language.
	\item Then we will be able to express all 4 kinds of dependencies using plain old functions.
\end{itemize}
\end{frame}

\begin{frame}{What does ``first-class'' mean?}
\begin{itemize}
	\item \textbf{The concept of ``first-class'' is neither precisely defined nor exact}. Rather, it's more of a functional programming folklore that obeys the ``I know it when I see it'' principle.
	\item However there are some heuristics that can help you.
	\item \textbf{Something is first-class when it can be}:
	\item bound/assigned to variables.
	\item stored in data structures.
	\item passed to functions as an argument.
	\item returned from functions.
	\item constructed at runtime.
	\item nameless, i.e. it can exist without giving it any name.
\end{itemize}
\end{frame}

\begin{frame}{A type-based definition of ``first-class''}
\begin{itemize}
	\item Heuristics from previous slides are nice\dots
	\item but I prefer to think about first-class-ness in a different way, which is better from the functional programming point of view.
	\item For a given programming, \textbf{a concept $X$ is first-class if there is a type of all $X$s}, loosely speaking.
	\item This means that a language has first-class functions if for any two types $A$ and $B$ there is a type $A \to B$ of all functions from $A$ to $B$.
\end{itemize}
\end{frame}

\begin{frame}{The Universe of Types}
\begin{itemize}
	\item For types, this means that we need to have a \textbf{type of types}.
	\item And that's it -- we don't need anything else.
	\item Note: the phrase ``types of types'' sounds (and looks) bad, so we will call it \textbf{the universe of types}, or in short, just \textbf{the universe}.
	\item Because types are first-class in F*, we can assign them to variables, pass them to functions as arguments and return them from functions, and even compute types by recursion.
\end{itemize}
\end{frame}

\begin{frame}{Type families}
\begin{itemize}
	\item In the coming slides, we will often refer to \textbf{type families}.
	\item \textbf{A family of types indexed by type \m{a}} is just a function \m{a -> Type}.
	\item There can be many indices, like in \m{a -> b -> Type}.
	\item We have already seen examples in the last code snippet:
	\item \m{vec :\ Type -> nat -> Type} is a family of types whose members \m{vec a n} are lists of length \m{n} and elements of type \m{a}
	\item \m{matrix :\ Type -> nat -> nat -> Type} is a family of types whose members \m{matrix a n m} are $n \times m$ matrices with entries of type \m{a}.
\end{itemize}
\end{frame}

\begin{frame}{Code snippet no 2 - first-class types in F*}
\begin{itemize}
	\item It might a bit difficult to wrap your head around the idea of first-class types, so let's see how it plays out in F*.
	\item The code snippet can be found in \m{Lecture1/Code/Universe.fst}
\end{itemize}
\end{frame}

\section{Functions}

\begin{frame}{Dependent types by analogy}
\begin{itemize}
	\item We will introduce dependent types by analogy.
	\item \textbf{Each of the various kinds of dependent types out there is just a generalization of an ordinary non-dependent type that is well-known to functional programmers}:
	\item Dependent function types are a generalization of function types.
	\item Dependent pair types are a generalization of products.
	\item Dependent record types are a generalization of records.
	\item Inductive types are a generalization of algebraic data types.
\end{itemize}
\end{frame}

\begin{frame}{Non-dependent functions}
\begin{itemize}
	\item Recall how ordinary function types work in F\#.
	\item If \m{a :\ Type} is a type and \m{b :\ Type} is a type, then there is a type \m{a -> b :\ Type} of functions that take an element of \m{a} and return an element of \m{b}.
	\item We create functions of type \m{a -> b} by writing \m{fun (x :\ a) -> e} where \m{e} is an expression of type \m{b} in which \m{x} may occur.
	\item If we have a function \m{f :\ a -> b} and \m{x :\ a}, then we we can apply \m{f} to \m{x}, written \m{f x}, to get an element of type \m{b}.
\end{itemize}
\end{frame}

\begin{frame}{Dependent functions}
\begin{itemize}
	\item Now, watch the analogy unfold\dots
	\item If \m{a :\ Type} is a type and \textbf{\m{b :\ a -> Type} is a family of types}, then there is a type \textbf{\m{(x :\ a) -> b x} of dependent functions} which take an element of \m{a} \textbf{named \m{x}} and return an element of \m{b x}.
	\item We create functions of type \m{(x :\ a) -> b x} by writing \m{fun (x :\ a) -> e} where \m{e} is an expression of type \m{b x} in which \m{x} may occur.
	\item If we have a function \m{f :\ (x :\ a) -> b x} and \m{x :\ a}, then we can apply \m{f} to \m{x}, written \m{f x}, to get an element of type \m{b x}.
	\item Hint: it's probably easiest to pronounce \m{(x :\ a) -> b x} as ``for all \m{x} of type \m{a}, \m{b} of \m{x}''. Thus is revealed the connection to logic, which we will see in the next lecture.
\end{itemize}
\end{frame}

\begin{frame}{More dependent functions}
\begin{itemize}
	\item Of course, we can iterate the dependent function type to get a type of functions whose output type dependent on the value of many inputs.
	\item \m{(x :\ a) -> b x}
	\item \m{(x :\ a) -> ((y :\ b x) -> c x y)}
	\item Dependent function type associates to the right, just like ordinary function type, so we can drop the parentheses. We can also drop all but the last arrow.
	\item \m{(x :\ a) (y :\ b x) (z :\ c x y) -> d x y z}
	\item \m{(x :\ a) (y :\ b x) (z :\ c x y) (w : d x y z) -> e x y z w}
	\item etc.
\end{itemize}
\end{frame}

\begin{frame}{Code snippet no 3 - dependent functions in F*}
\begin{itemize}
	\item Let's see how to use dependent functions in F*.
	\item See the code snippet \m{Lecture1/Code/DependentFunctions.fst}
\end{itemize}
\end{frame}

\section{Records}

\begin{frame}{Non-dependent pairs}
\begin{itemize}
	\item Recall how ordinary pairs work in F\#.
	\item If \m{a :\ Type} is a type and \m{b :\ Type} is a type, then there is a type \m{a * b :\ Type} of pairs.
	\item To create a pair, we write \m{(x, y)} where \m{x} is of type \m{a} and \m{y} is of type \m{b}.
	\item To use a pair \m{p :\ a * b}, we use projections -- we have \m{fst p :\ a} and \m{snd p :\ b}.
	\item We can also pattern match on pairs.
\end{itemize}
\end{frame}

\begin{frame}{Dependent pairs}
\begin{itemize}
	\item Now, watch the analogy unfold\dots
	\item If \m{a :\ Type} is a type and \textbf{\m{b :\ a -> Type} is a family of types}, then there is \textbf{a type \m{(x :\ a) \& b x :\ Type} of dependent pairs}.
	\item To create a dependent pair, we write \m{(| x, y |)} where \m{x} is of type \m{a} \textbf{and \m{y} is of type \m{b x}}.
	\item To use a pair \m{p :\ (x :\ a) \& b x}, we use projections -- we have \m{fst p :\ a} and \m{snd p :\ b (fst p)} (\textbf{note that the type of the second projection depends on the value of the first projection}).
	\item We can also pattern match on dependent pairs.
\end{itemize}
\end{frame}

\begin{frame}{More dependent pairs}
\begin{itemize}
	\item \textbf{We can iterate the dependent pair type}, while dropping unneeded parentheses -- analogously to what we did for dependent functions.
	\item \m{(x :\ a) \& b x}
	\item \m{(x :\ a) \& (y :\ b x) \& c x y}
	\item \m{(x :\ a) \& (y :\ b x) \& (z :\ c x y) \& d x y z}
	\item \textbf{But using iterated dependent pairs is very inconvenient!}
	\item To access component of a dependent quadruple \m{p} we would have to write \m{fst p}, \m{fst (snd p)}, \m{fst (snd (snd p))} and \m{snd (snd (snd p))}.
\end{itemize}
\end{frame}

\begin{frame}{Dependent record types}
\begin{itemize}
	\item There's a better way than iterating dependent pair types: dependent record types.
	\item A record is basically a labeled tuple.
	\item \textbf{A dependent record is basically a labeled dependent tuple}.
	\item This means that the TYPES of later fields in a dependent record can depend on the VALUES of earlier fields.
\end{itemize}
\end{frame}

\begin{frame}{Code snippet no 4 - dependent records in F*}
\begin{itemize}
	\item Let's see how dependent records work in F*.
	\item See the code snippet \m{Lecture1/Code/DependentRecords.fst}
\end{itemize}
\end{frame}

\section{Inductives}

\begin{frame}{Inductive types refresher}
\begin{itemize}
	\item Recall how ordinary inductive types work in F\# (where they are called discriminated unions; in Haskell, they are knwon as algebraic data types).
	\item To define an inductive type \m{I :\ Type}, we list its constructors.
	\item The constructors are ordinary functions which take some arguments (which may be of type \m{I}, i.e. the one that is being defined) and return an element of \m{I}.
	\item To create an element of \m{I}, we use one of the constructors and provide it with the arguments it requires.
	\item To use an element of \m{I}, we pattern match on it and for each case we provide an expression which will be computed if that case matches.
\end{itemize}
\end{frame}

\begin{frame}{Inductive families 1/2}
\begin{itemize}
	\item Now watch the analogy unfold...
	\item To define an \textbf{inductive family} \m{I : a -> Type}, we list its constructors. Here \m{a} is some type that is already defined.
	\item The constructors are \textbf{dependent functions} which take some arguments (which \textbf{may be of type} \m{I y} for some \m{y :\ a}) and \textbf{return an element of the type} \m{I x}, for some \m{x :\ a}.
	\item To create an element of \m{I x}, we use one of the constructors and provide it with the arguments it requires.
	\item To use an element of \m{I x}, we pattern match on it and for each case we provide an expression which will be computed if that case matches.
\end{itemize}
\end{frame}

\begin{frame}{Inductive families 2/2}
\begin{itemize}
	\item This time it's a bit harder to spot the analogy, so let's elaborate on it.
	\item Instead of a single type \m{I :\ Type}, we define a \textbf{family of types} \m{I :\ a -> Type} all at once.
	\item In this context, values of type \m{a} are called \textbf{indices} of the family \m{I}.
	\item We define a \textbf{separate type for each possible index}.
	\item To create a value that belongs to \textbf{some type} \m{I x} in the family, a constructor may require an argument that belongs to \m{I y}, \textbf{a different type} in the family.
\end{itemize}
\end{frame}

\begin{frame}{Code snippet no 5 - inductive families in F*}
\begin{itemize}
	\item Let's see how inductive families work in F*.
	\item See the code snippet \m{Lecture1/Code/InductiveFamilies.fst}
\end{itemize}
\end{frame}

\begin{frame}{Summary}
\begin{itemize}
	\item Dependent types are types that can depend on values.
	\item In dependently typed languages:
	\item There is a universe -- a type whose elements are themselves types.
	\item Dependent functions which are just like ordinary functions, but their output TYPE can depend on the VALUE of their input.
	\item Dependent record types are just like ordinary records, but the TYPES of later fields can depend on the VALUE of earlier fields.
	\item Inductive families are just like ordinary inductive types, but the TYPES in the family can depend on the VALUE of the index.
\end{itemize}
\end{frame}

\section{Refinement types}

\begin{frame}{The problem of richness}
\begin{itemize}
    \item In dependently typed languages there is a lot of types.
    \item This is a blessing, because we can express all the complicated types and properties we need in order to guarantee correctness of our programs.
    \item But the richness of types also causes problems: it is often the case that there are many ways to define essentially the same type.
\end{itemize}
\end{frame}

\begin{frame}{The various faces of a \m{vec}tor 1/2}
\begin{itemize}
    \item We have already seen two incarnations of the type \m{vec a n} of vectors:
    \item Functional, recursive: by recursion on the index.
    \item Inductive, intrinsic: as an inductive family.
    \item But there are at least two more definitions:
    \item Functional, nonrecursive: as a function with domain \m{fin n}.
    \item Inductive, extrinsic: as a pair of a list and a proof that it's length is equal to \m{n}.
    \item \textbf{Which one should we use?}
\end{itemize}
\end{frame}

\begin{frame}{The various faces of a \m{vec}tor 2/2}
\begin{itemize}
	\item A summary of cons of each:
	\item Functional, recursive: ugly.
	\item Inductive, intrinsic: code duplication -- it is necessary to reimplement common list functions (append, map, etc.).
    \item Functional, nonrecursive: ugly, higher-order representation, very difficult to implement functions (try to implement append if you don't believe me).
    \item Inductive, extrinsic: a lot of boilerplate concerned with passing proofs around; need to reimplement list functions by wrapping them.
\end{itemize}
\end{frame}

\begin{frame}{Refinement types}
\begin{itemize}
    \item \textbf{Refinement types are NOT dependent types!}
    \item A refinement is just a different name for a function that returns bool.
    \item A refinement type is a type paired with a refinement.
    \item In F* syntax: \m{x : a{p x}} where \m{p : a -> bool}.
\end{itemize}
\end{frame}

\begin{frame}{Code snippet no 6 - refinement types in F*}
\begin{itemize}
	\item Let's see how refinement types work in F*.
	\item See the code snippet \m{Lecture1/Code/Refinements.fst}
\end{itemize}
\end{frame}

\section{Life of Pi}

\begin{frame}{Pi type and multiplication}
\begin{itemize}
	\item The dependent function type \textbf{is also known as the Pi type}.
	\item \textbf{This name comes from a notation}: \m{(x :\ a) -> b x} is sometimes written as $\displaystyle \prod_{x :\ a} b(x)$.
	\item \textbf{This notation comes from an analogy with multiplication}. In math $\displaystyle \prod_{k = 0}^n a_k$ means $a_0 \cdot a_1 \cdot ... \cdot a_n$.
	\item \textbf{We can think about dependent function types in this way too}. For example, the type \m{(x :\ bool) -> p x} is equivalent to \m{p true * p false}.
	\item The result of multiplication is called a product, hence the dependent function type \textbf{is also known as the dependent product type}.
	\item As it turns out, the dependent function type \textbf{generalizes both the ordinary function type and the product type}, but in different ways.
\end{itemize}
\end{frame}

\begin{frame}{Sigma type and addition}
\begin{itemize}
	\item The dependent pair type \textbf{is also known as the Sigma type}.
	\item \textbf{This name comes from a notation}: \m{(x :\ a) \& b x} is sometimes written as $\displaystyle \sum_{x :\ a} b(x)$.
	\item \textbf{This notation comes from an analogy with addition}. In math $\displaystyle \sum_{k = 0}^n a_k$ means $a_0 + a_1 + ... + a_n$.
	\item \textbf{We can think about dependent pair types in this way too}. For example, the type \m{(x :\ bool) \& p x} is equivalent to \m{p true + p false} (where \m{+} just means a simple tagged union).
	\item The result of addition is called a sum, hence the dependent pair type \textbf{is also known as the dependent sum type}.
	\item As it turns out, the dependent pair type \textbf{generalizes both the product type and the sum type}, but in different ways.
\end{itemize}
\end{frame}

\begin{frame}{Inductive types and polynomials 1/2}
\begin{itemize}
	\item An inductive type is \textbf{EITHER} constructor 1 applied to arguments \m{x1} \textbf{and} \m{x2} \dots \textbf{and} \m{xN} \textbf{OR} constructor 2 applied to arguments \dots \textbf{OR} constructor M applied to arguments \dots
	\item In math, OR means \textbf{addition}, whereas AND means \textbf{multiplication}.
	\item So, an inductive type boils down to a \textbf{Sum of Products}.
	\item These products are made of two kinds of arguments: recursive arguments (whose type is the inductive type that is being defined) and non-recursive ones.
	\item If you think about it long enough, \textbf{inductive types correspond to polynomials}.
\end{itemize}
\end{frame}

\begin{frame}{Inductive types and polynomials 2/2}
\begin{itemize}
	\item This could be hard to swallow, so let's see examples.
	\item Lists satisfy the equation $\m{List}(A) = 1 + A \times \m{List}(A)$.
	\item Here $1$ corresponds to the \m{nil} constructor, whereas the $A$ and $\m{List}(A)$ on the right correspond to the arguments of the \m{cons} constructor.
	\item This corresponds to the polynomial $F(X) = 1 + A \times X$.
	\item $\m{List}(A)$ is the least fixed point of this polynomial, i.e. the smallest type $X$ that satisfies $F(X) = X$.
	\item Here ``fixed point'' corresponds to the fact that we create lists using constructors (\m{nil} and \m{cons}), whereas ``least'' corresponds to the fact that all lists are made of finitely many constructors.
\end{itemize}
\end{frame}

\end{document}